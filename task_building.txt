Based on my analysis of the repository, here's how you can create new tasks and record expert
  trajectories in RLBench:

  Creating New Tasks

  Creating a new task in RLBench involves a combination of Python scripting and using the provided
  tools. The recommended way to start is by using the task_builder.py script.

  Here's a general workflow:

   1. Use the Task Builder Tool:
       * Run the tools/task_builder.py script. This will create a new task file in rlbench/tasks and a
         corresponding .ttt (V-REP scene) file in rlbench/task_ttms.
       * The script will prompt you for the task name and the number of variations.

   2. Edit the Task Python File:
       * Open the newly created Python file in rlbench/tasks.
       * The file will contain a class for your new task that inherits from rlbench.backend.task.Task.
       * You will need to implement the following key methods:
           * init_task(self): This is where you define the objects that will be present in your task's
             scene. You can add primitive shapes, import models, and set their properties.
           * init_episode(self, index: int): This method is called at the start of each episode. It's used
             to define the variations of your task. The index parameter tells you which variation to set
             up. You can change object positions, colors, textures, etc.
           * variation_count(self) -> int: This should return the total number of variations for your task.
           * You can also define waypoints and success conditions within your task file. The tutorials
             tutorials/simple_task.md and tutorials/complex_task.md provide excellent examples of how to do
             this.


   3. Edit the Task Scene File (.ttt):
       * The .ttt file in rlbench/task_ttms is the scene file for your task. You can open it in the V-REP
         editor to visually place objects, define paths, and set up the environment.

  Recording Expert Trajectories

  Expert trajectories, referred to as "demos" in RLBench, are crucial for imitation learning and some
  reinforcement learning algorithms. Here's how they are recorded:

   1. Data Collection:
       * The primary tool for collecting demonstrations is rlbench/dataset_generator.py.
       * This script allows you to step through each variation of a task and record a demonstration.
       * You can control the robot using a VR headset for human-like demonstrations or by scripting the
         robot's actions.

   2. Demonstration Storage:
       * The recorded demonstrations are saved as pickle files (.pkl) in the RLBENCH_DATA directory.
       * Each demo file contains a list of observations for each step in the trajectory. These
         observations include camera images, joint positions, gripper state, and other sensor data. The
         rlbench/demo.py file defines the structure of the Demo object.

   3. Cinematic Recordings:
       * For creating high-quality videos of your tasks, you can use the tools/cinematic_recorder.py
         script. This tool allows you to record smooth, cinematic videos of your tasks being performed,
         which can be useful for presentations and debugging.

  In summary, you would first define your task and its variations, and then use the provided tools to
  record expert demonstrations for each of those variations. The tutorials in the tutorials directory
  are a great resource for getting started with both of these processes.